{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from itertools import chain\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project WP1-2\n",
    "### code 1: Clean journey and remove duplicates\n",
    "<span style='font-family:\"Times New Roman\"'> <span styel=''> \n",
    "This code is used to extract the \"PortList.csv\" information from \"fleet_trade_journeys.csv\"; \n",
    "Duplicate terminals are defined as terminals with the same names but in different countries. There are 38 duplicated entries in the dataset \"PortList.xlsx\" from Gang, which needs to be improved;\n",
    "The original dataset is \"fleet_trade_journeys.csv\";\n",
    "### Basic steps: \n",
    "    a) Load data;\n",
    "    b) Check duplicate entries in \"portList.xlsx\";\n",
    "    c) Extract all duplicate terminals/and its inforamtion from original dataset.\n",
    "    d) Find the number of calls for new cleaned dataset\n",
    "    e) Save the cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Step a):  load data in both \"fleet_trade_journeys.csv\" and \"PortList.xlsx\", and check the statistic information of data.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journey=pd.read_csv(\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/fleet_trade_journeys.csv\")\n",
    "df_ports=pd.ExcelFile(\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/PortList.xlsx\")\n",
    "df_ports=df_ports.parse(header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journey_id</th>\n",
       "      <th>ship_id</th>\n",
       "      <th>ais_ship_id</th>\n",
       "      <th>journey_laden</th>\n",
       "      <th>journey_start_stoppage_id</th>\n",
       "      <th>journey_start_timestamp</th>\n",
       "      <th>journey_start_draft</th>\n",
       "      <th>journey_start_latitude</th>\n",
       "      <th>journey_start_longitude</th>\n",
       "      <th>journey_start_location_type</th>\n",
       "      <th>...</th>\n",
       "      <th>journey_end_location_name</th>\n",
       "      <th>journey_end_location_country</th>\n",
       "      <th>journey_end_location_unlocode</th>\n",
       "      <th>journey_distance_nm</th>\n",
       "      <th>journey_underway_calc_avg_speed</th>\n",
       "      <th>journey_processed</th>\n",
       "      <th>journey_current</th>\n",
       "      <th>journey_estimated_cargo_tons</th>\n",
       "      <th>journey_underway_distance</th>\n",
       "      <th>journey_underway_time_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286559091</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>886369008</td>\n",
       "      <td>2013-12-30 05:34:03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.45277</td>\n",
       "      <td>140.92767</td>\n",
       "      <td>Port</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeosu</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>KRYOS</td>\n",
       "      <td>1247.352457</td>\n",
       "      <td>13.959216</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>98235</td>\n",
       "      <td>1195.141506</td>\n",
       "      <td>85.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286559092</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>886369009</td>\n",
       "      <td>2014-01-07 13:30:04</td>\n",
       "      <td>14.2</td>\n",
       "      <td>34.71473</td>\n",
       "      <td>127.81125</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>...</td>\n",
       "      <td>De Kastri</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUDKA</td>\n",
       "      <td>1251.511628</td>\n",
       "      <td>13.074002</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1233.310535</td>\n",
       "      <td>94.333056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>286559093</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>886369012</td>\n",
       "      <td>2014-01-19 01:02:19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.48012</td>\n",
       "      <td>140.92478</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>...</td>\n",
       "      <td>Ulsan</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>KRUSN</td>\n",
       "      <td>1166.283499</td>\n",
       "      <td>14.453006</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>98235</td>\n",
       "      <td>1132.023627</td>\n",
       "      <td>78.324444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286559094</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>886369014</td>\n",
       "      <td>2014-01-25 05:06:44</td>\n",
       "      <td>14.2</td>\n",
       "      <td>35.44117</td>\n",
       "      <td>129.39453</td>\n",
       "      <td>Port</td>\n",
       "      <td>...</td>\n",
       "      <td>De Kastri</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUDKA</td>\n",
       "      <td>1339.352542</td>\n",
       "      <td>13.024184</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1197.562825</td>\n",
       "      <td>91.949167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286559095</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>886369018</td>\n",
       "      <td>2014-02-05 12:23:14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.48157</td>\n",
       "      <td>140.92332</td>\n",
       "      <td>Port</td>\n",
       "      <td>...</td>\n",
       "      <td>Gwangyang</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>KRKAN</td>\n",
       "      <td>1299.165114</td>\n",
       "      <td>13.671880</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>98235</td>\n",
       "      <td>1288.684831</td>\n",
       "      <td>94.258056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   journey_id  ship_id  ais_ship_id  journey_laden  journey_start_stoppage_id  \\\n",
       "0   286559091  9301421           97              1                  886369008   \n",
       "1   286559092  9301421           97              0                  886369009   \n",
       "2   286559093  9301421           97              1                  886369012   \n",
       "3   286559094  9301421           97              0                  886369014   \n",
       "4   286559095  9301421           97              1                  886369018   \n",
       "\n",
       "  journey_start_timestamp  journey_start_draft  journey_start_latitude  \\\n",
       "0     2013-12-30 05:34:03                  9.0                51.45277   \n",
       "1     2014-01-07 13:30:04                 14.2                34.71473   \n",
       "2     2014-01-19 01:02:19                  9.0                51.48012   \n",
       "3     2014-01-25 05:06:44                 14.2                35.44117   \n",
       "4     2014-02-05 12:23:14                  9.0                51.48157   \n",
       "\n",
       "   journey_start_longitude journey_start_location_type  ...  \\\n",
       "0                140.92767                        Port  ...   \n",
       "1                127.81125                   Anchorage  ...   \n",
       "2                140.92478                   Anchorage  ...   \n",
       "3                129.39453                        Port  ...   \n",
       "4                140.92332                        Port  ...   \n",
       "\n",
       "  journey_end_location_name journey_end_location_country  \\\n",
       "0                     Yeosu                  South Korea   \n",
       "1                 De Kastri                       Russia   \n",
       "2                     Ulsan                  South Korea   \n",
       "3                 De Kastri                       Russia   \n",
       "4                 Gwangyang                  South Korea   \n",
       "\n",
       "  journey_end_location_unlocode  journey_distance_nm  \\\n",
       "0                         KRYOS          1247.352457   \n",
       "1                         RUDKA          1251.511628   \n",
       "2                         KRUSN          1166.283499   \n",
       "3                         RUDKA          1339.352542   \n",
       "4                         KRKAN          1299.165114   \n",
       "\n",
       "  journey_underway_calc_avg_speed    journey_processed  journey_current  \\\n",
       "0                       13.959216  2019-03-28 06:53:38                0   \n",
       "1                       13.074002  2019-03-28 06:53:38                0   \n",
       "2                       14.453006  2019-03-28 06:53:38                0   \n",
       "3                       13.024184  2019-03-28 06:53:38                0   \n",
       "4                       13.671880  2019-03-28 06:53:38                0   \n",
       "\n",
       "   journey_estimated_cargo_tons journey_underway_distance  \\\n",
       "0                         98235               1195.141506   \n",
       "1                             0               1233.310535   \n",
       "2                         98235               1132.023627   \n",
       "3                             0               1197.562825   \n",
       "4                         98235               1288.684831   \n",
       "\n",
       "  journey_underway_time_hours  \n",
       "0                   85.616667  \n",
       "1                   94.333056  \n",
       "2                   78.324444  \n",
       "3                   91.949167  \n",
       "4                   94.258056  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_journey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 501331 entries, 0 to 501330\n",
      "Data columns (total 29 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   journey_id                       501331 non-null  int64  \n",
      " 1   ship_id                          501331 non-null  int64  \n",
      " 2   ais_ship_id                      501331 non-null  int64  \n",
      " 3   journey_laden                    501331 non-null  int64  \n",
      " 4   journey_start_stoppage_id        501331 non-null  int64  \n",
      " 5   journey_start_timestamp          501331 non-null  object \n",
      " 6   journey_start_draft              501331 non-null  float64\n",
      " 7   journey_start_latitude           501331 non-null  float64\n",
      " 8   journey_start_longitude          501331 non-null  float64\n",
      " 9   journey_start_location_type      501292 non-null  object \n",
      " 10  journey_start_location_name      501292 non-null  object \n",
      " 11  journey_start_location_country   500725 non-null  object \n",
      " 12  journey_start_location_unlocode  496238 non-null  object \n",
      " 13  journey_end_stoppage_id          499683 non-null  float64\n",
      " 14  journey_end_timestamp            499683 non-null  object \n",
      " 15  journey_end_draft                499683 non-null  float64\n",
      " 16  journey_end_latitude             499683 non-null  float64\n",
      " 17  journey_end_longitude            499683 non-null  float64\n",
      " 18  journey_end_location_type        499577 non-null  object \n",
      " 19  journey_end_location_name        499577 non-null  object \n",
      " 20  journey_end_location_country     498995 non-null  object \n",
      " 21  journey_end_location_unlocode    495225 non-null  object \n",
      " 22  journey_distance_nm              501331 non-null  float64\n",
      " 23  journey_underway_calc_avg_speed  501331 non-null  float64\n",
      " 24  journey_processed                501331 non-null  object \n",
      " 25  journey_current                  501331 non-null  int64  \n",
      " 26  journey_estimated_cargo_tons     501331 non-null  int64  \n",
      " 27  journey_underway_distance        501331 non-null  float64\n",
      " 28  journey_underway_time_hours      501331 non-null  float64\n",
      "dtypes: float64(11), int64(7), object(11)\n",
      "memory usage: 110.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_journey.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>journey_id</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>2.875341e+08</td>\n",
       "      <td>3.485398e+06</td>\n",
       "      <td>2.734272e+08</td>\n",
       "      <td>2.841194e+08</td>\n",
       "      <td>2.865120e+08</td>\n",
       "      <td>2.913336e+08</td>\n",
       "      <td>2.924330e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ship_id</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>9.430823e+06</td>\n",
       "      <td>2.884781e+05</td>\n",
       "      <td>6.329044e+06</td>\n",
       "      <td>9.274317e+06</td>\n",
       "      <td>9.351452e+06</td>\n",
       "      <td>9.467732e+06</td>\n",
       "      <td>1.010406e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ais_ship_id</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>1.366647e+05</td>\n",
       "      <td>2.280218e+05</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>1.541800e+04</td>\n",
       "      <td>4.786100e+04</td>\n",
       "      <td>1.018680e+05</td>\n",
       "      <td>1.030385e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_laden</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>5.441255e-01</td>\n",
       "      <td>4.980496e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_start_stoppage_id</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>8.875433e+08</td>\n",
       "      <td>7.886687e+06</td>\n",
       "      <td>8.530603e+08</td>\n",
       "      <td>8.797651e+08</td>\n",
       "      <td>8.862683e+08</td>\n",
       "      <td>8.956614e+08</td>\n",
       "      <td>8.988223e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_start_draft</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>9.404650e+00</td>\n",
       "      <td>2.022961e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.900000e+00</td>\n",
       "      <td>1.080000e+01</td>\n",
       "      <td>2.550000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_start_latitude</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>2.582539e+01</td>\n",
       "      <td>2.236658e+01</td>\n",
       "      <td>-5.327544e+01</td>\n",
       "      <td>1.265715e+01</td>\n",
       "      <td>2.974437e+01</td>\n",
       "      <td>4.060922e+01</td>\n",
       "      <td>7.655333e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_start_longitude</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>2.232075e+01</td>\n",
       "      <td>7.662933e+01</td>\n",
       "      <td>-1.717647e+02</td>\n",
       "      <td>-4.632785e+01</td>\n",
       "      <td>2.350883e+01</td>\n",
       "      <td>1.035428e+02</td>\n",
       "      <td>1.793667e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_end_stoppage_id</th>\n",
       "      <td>499683.0</td>\n",
       "      <td>8.875967e+08</td>\n",
       "      <td>7.901345e+06</td>\n",
       "      <td>8.530603e+08</td>\n",
       "      <td>8.797677e+08</td>\n",
       "      <td>8.862969e+08</td>\n",
       "      <td>8.956848e+08</td>\n",
       "      <td>8.988223e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_end_draft</th>\n",
       "      <td>499683.0</td>\n",
       "      <td>9.417424e+00</td>\n",
       "      <td>1.996592e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.900000e+00</td>\n",
       "      <td>1.080000e+01</td>\n",
       "      <td>2.550000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_end_latitude</th>\n",
       "      <td>499683.0</td>\n",
       "      <td>2.582708e+01</td>\n",
       "      <td>2.237273e+01</td>\n",
       "      <td>-5.327544e+01</td>\n",
       "      <td>1.265715e+01</td>\n",
       "      <td>2.974275e+01</td>\n",
       "      <td>4.062448e+01</td>\n",
       "      <td>7.655333e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_end_longitude</th>\n",
       "      <td>499683.0</td>\n",
       "      <td>2.214519e+01</td>\n",
       "      <td>7.656936e+01</td>\n",
       "      <td>-1.717647e+02</td>\n",
       "      <td>-4.632958e+01</td>\n",
       "      <td>2.338147e+01</td>\n",
       "      <td>1.035417e+02</td>\n",
       "      <td>1.793667e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_distance_nm</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>1.918132e+03</td>\n",
       "      <td>3.639194e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.450470e+02</td>\n",
       "      <td>1.098128e+03</td>\n",
       "      <td>2.511687e+03</td>\n",
       "      <td>1.940132e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_underway_calc_avg_speed</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>1.137173e+01</td>\n",
       "      <td>8.492629e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.057633e+01</td>\n",
       "      <td>1.177645e+01</td>\n",
       "      <td>1.258236e+01</td>\n",
       "      <td>5.422787e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_current</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>3.287249e-03</td>\n",
       "      <td>5.724028e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_estimated_cargo_tons</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>2.825692e+04</td>\n",
       "      <td>3.209224e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.489000e+04</td>\n",
       "      <td>4.417500e+04</td>\n",
       "      <td>1.202000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_underway_distance</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>1.874322e+03</td>\n",
       "      <td>3.620399e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.179276e+02</td>\n",
       "      <td>1.052677e+03</td>\n",
       "      <td>2.449303e+03</td>\n",
       "      <td>1.940126e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journey_underway_time_hours</th>\n",
       "      <td>501331.0</td>\n",
       "      <td>1.570609e+02</td>\n",
       "      <td>1.896403e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.696014e+01</td>\n",
       "      <td>9.120472e+01</td>\n",
       "      <td>2.062233e+02</td>\n",
       "      <td>1.748640e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    count          mean           std  \\\n",
       "journey_id                       501331.0  2.875341e+08  3.485398e+06   \n",
       "ship_id                          501331.0  9.430823e+06  2.884781e+05   \n",
       "ais_ship_id                      501331.0  1.366647e+05  2.280218e+05   \n",
       "journey_laden                    501331.0  5.441255e-01  4.980496e-01   \n",
       "journey_start_stoppage_id        501331.0  8.875433e+08  7.886687e+06   \n",
       "journey_start_draft              501331.0  9.404650e+00  2.022961e+00   \n",
       "journey_start_latitude           501331.0  2.582539e+01  2.236658e+01   \n",
       "journey_start_longitude          501331.0  2.232075e+01  7.662933e+01   \n",
       "journey_end_stoppage_id          499683.0  8.875967e+08  7.901345e+06   \n",
       "journey_end_draft                499683.0  9.417424e+00  1.996592e+00   \n",
       "journey_end_latitude             499683.0  2.582708e+01  2.237273e+01   \n",
       "journey_end_longitude            499683.0  2.214519e+01  7.656936e+01   \n",
       "journey_distance_nm              501331.0  1.918132e+03  3.639194e+03   \n",
       "journey_underway_calc_avg_speed  501331.0  1.137173e+01  8.492629e+00   \n",
       "journey_current                  501331.0  3.287249e-03  5.724028e-02   \n",
       "journey_estimated_cargo_tons     501331.0  2.825692e+04  3.209224e+04   \n",
       "journey_underway_distance        501331.0  1.874322e+03  3.620399e+03   \n",
       "journey_underway_time_hours      501331.0  1.570609e+02  1.896403e+02   \n",
       "\n",
       "                                          min           25%           50%  \\\n",
       "journey_id                       2.734272e+08  2.841194e+08  2.865120e+08   \n",
       "ship_id                          6.329044e+06  9.274317e+06  9.351452e+06   \n",
       "ais_ship_id                      9.700000e+01  1.541800e+04  4.786100e+04   \n",
       "journey_laden                    0.000000e+00  0.000000e+00  1.000000e+00   \n",
       "journey_start_stoppage_id        8.530603e+08  8.797651e+08  8.862683e+08   \n",
       "journey_start_draft              0.000000e+00  8.000000e+00  8.900000e+00   \n",
       "journey_start_latitude          -5.327544e+01  1.265715e+01  2.974437e+01   \n",
       "journey_start_longitude         -1.717647e+02 -4.632785e+01  2.350883e+01   \n",
       "journey_end_stoppage_id          8.530603e+08  8.797677e+08  8.862969e+08   \n",
       "journey_end_draft                0.000000e+00  8.000000e+00  8.900000e+00   \n",
       "journey_end_latitude            -5.327544e+01  1.265715e+01  2.974275e+01   \n",
       "journey_end_longitude           -1.717647e+02 -4.632958e+01  2.338147e+01   \n",
       "journey_distance_nm              0.000000e+00  4.450470e+02  1.098128e+03   \n",
       "journey_underway_calc_avg_speed  0.000000e+00  1.057633e+01  1.177645e+01   \n",
       "journey_current                  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "journey_estimated_cargo_tons     0.000000e+00  0.000000e+00  2.489000e+04   \n",
       "journey_underway_distance        0.000000e+00  4.179276e+02  1.052677e+03   \n",
       "journey_underway_time_hours      0.000000e+00  3.696014e+01  9.120472e+01   \n",
       "\n",
       "                                          75%           max  \n",
       "journey_id                       2.913336e+08  2.924330e+08  \n",
       "ship_id                          9.467732e+06  1.010406e+07  \n",
       "ais_ship_id                      1.018680e+05  1.030385e+06  \n",
       "journey_laden                    1.000000e+00  1.000000e+00  \n",
       "journey_start_stoppage_id        8.956614e+08  8.988223e+08  \n",
       "journey_start_draft              1.080000e+01  2.550000e+01  \n",
       "journey_start_latitude           4.060922e+01  7.655333e+01  \n",
       "journey_start_longitude          1.035428e+02  1.793667e+02  \n",
       "journey_end_stoppage_id          8.956848e+08  8.988223e+08  \n",
       "journey_end_draft                1.080000e+01  2.550000e+01  \n",
       "journey_end_latitude             4.062448e+01  7.655333e+01  \n",
       "journey_end_longitude            1.035417e+02  1.793667e+02  \n",
       "journey_distance_nm              2.511687e+03  1.940132e+06  \n",
       "journey_underway_calc_avg_speed  1.258236e+01  5.422787e+03  \n",
       "journey_current                  0.000000e+00  1.000000e+00  \n",
       "journey_estimated_cargo_tons     4.417500e+04  1.202000e+05  \n",
       "journey_underway_distance        2.449303e+03  1.940126e+06  \n",
       "journey_underway_time_hours      2.062233e+02  1.748640e+04  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_journey.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>Port Group</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>num of calls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Rio Cullen</td>\n",
       "      <td>Rio Cullen</td>\n",
       "      <td>East Sou.Ame</td>\n",
       "      <td>-52.804410</td>\n",
       "      <td>-68.208910</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Punta Loyola</td>\n",
       "      <td>Rio Cullen</td>\n",
       "      <td>East Sou.Ame</td>\n",
       "      <td>-51.606985</td>\n",
       "      <td>-69.019225</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Dunedin</td>\n",
       "      <td>Bluff</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>-45.875160</td>\n",
       "      <td>170.519330</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Comodoro Rivadavia</td>\n",
       "      <td>Caleta Cordova</td>\n",
       "      <td>East Sou.Ame</td>\n",
       "      <td>-45.860180</td>\n",
       "      <td>-67.389045</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Caleta Cordova</td>\n",
       "      <td>Caleta Cordova</td>\n",
       "      <td>East Sou.Ame</td>\n",
       "      <td>-45.773050</td>\n",
       "      <td>-67.320400</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country            Terminal      Port Group        Region  \\\n",
       "index                                                                  \n",
       "6        Argentina          Rio Cullen      Rio Cullen  East Sou.Ame   \n",
       "13       Argentina        Punta Loyola      Rio Cullen  East Sou.Ame   \n",
       "17     New Zealand             Dunedin           Bluff       Oceania   \n",
       "18       Argentina  Comodoro Rivadavia  Caleta Cordova  East Sou.Ame   \n",
       "19       Argentina      Caleta Cordova  Caleta Cordova  East Sou.Ame   \n",
       "\n",
       "             Lat         Lon  num of calls  \n",
       "index                                       \n",
       "6     -52.804410  -68.208910            56  \n",
       "13    -51.606985  -69.019225            14  \n",
       "17    -45.875160  170.519330            26  \n",
       "18    -45.860180  -67.389045            40  \n",
       "19    -45.773050  -67.320400           447  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Step b):  Check duplicate entries in \"portList.xlsx\".\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duplicate terminals extracted from Gang's file\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76 entries, 4743 to 4780\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country       76 non-null     object \n",
      " 1   Terminal      76 non-null     object \n",
      " 2   Port Group    76 non-null     object \n",
      " 3   Region        76 non-null     object \n",
      " 4   Lat           76 non-null     float64\n",
      " 5   Lon           76 non-null     float64\n",
      " 6   num of calls  76 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 4.8+ KB\n",
      "None\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "The duplicated index of terminals:\n",
      " [4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4775, 4776, 4777, 4778, 4779, 4780]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "The corresponding duplicated terminals:\n",
      " ['Obskaya Bay', 'LK Volga', 'Pevek', 'Koartac', 'Strivewell Island', 'Kokkola Deep Port', 'Hvalfjordur', 'Arctic Gate', 'Slovag', 'Valdez Marine Terminal', 'Fuglafjordur', 'Anchorage Terminal 3', 'Draugen', 'Heidrun', 'Uddebo Oil Terminal', 'Skipavik Gulen', 'Helguvik', 'Prirazlomnoye', 'Ronnskar', 'Anchorage POL 1 Terminal', 'Runavik', 'RPK 3', 'Kristiansund', 'Mongstad Refinery', 'North Star Bugt', 'Norne', 'Bugrino', 'Melkoya', 'Rypefjord', 'Tahkoluoto Liquid Terminal', 'RPK 1', 'Anchorage POL 2 Terminal', 'Yamal LNG Terminal', 'Knarr Field', 'RPK Nord', 'Harnosand', 'Talagi Oil Terminal', 'Sabetta']\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "The number of duplicated terminals based on this file:\n",
      "38\n",
      "38\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "We found that the overall number of journey starting from 'Valdez Marine Terminal' is 207,\n",
      " all belong to the country: \n",
      " United States of America    207\n",
      "Name: journey_start_location_country, dtype: int64\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "The same situation with the other terminals.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "Therefore, the so-called duplicated terminals are not correct.\n",
      "A entire cleanning of the journey dataset is needed!\n"
     ]
    }
   ],
   "source": [
    "# obtain duplicate terminals based on index\n",
    "# then concatenate them into a dataframe\n",
    "pd_dupPorts=pd.concat(g for _, g in df_ports.groupby(\"index\") if len(g) > 1)\n",
    "print (\"The duplicate terminals extracted from Gang's file\")\n",
    "print (\"-------------------------------------------------------------------------------------------------------------\")\n",
    "print (pd_dupPorts.info())\n",
    "print (\"-------------------------------------------------------------------------------------------------------------\")\n",
    "print ('\\n')\n",
    "\n",
    "# extract duplicate terminals and their indices\n",
    "ix_dup=pd_dupPorts.index\n",
    "ix_dup=ix_dup.values\n",
    "ix_dup=list(set(ix_dup))\n",
    "terminal_dup=pd_dupPorts.Terminal\n",
    "terminal_dup=terminal_dup.values\n",
    "terminal_dup=list(set(terminal_dup))\n",
    "\n",
    "print (\"The duplicated index of terminals:\\n\",ix_dup)\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"The corresponding duplicated terminals:\\n\",terminal_dup)\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"The number of duplicated terminals based on this file:\")\n",
    "print (len(ix_dup))\n",
    "print (len(terminal_dup))\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "# double check for these duplicated terminals in the original file \"fleet_trade_journeys.csv\".\n",
    "\n",
    "df_journeyLoc=df_journey[[\"journey_start_location_type\",\"journey_start_location_country\",\n",
    "            \"journey_start_location_name\",\"journey_start_latitude\",  \"journey_start_longitude\", \n",
    "            \"journey_end_location_type\",\"journey_end_location_country\",\"journey_end_location_name\",\n",
    "             \"journey_end_latitude\",  \"journey_end_longitude\"]]\n",
    "# take the duplicated case \"Valdez Marine Terminal\" for an example, we check if it is a read duplicated one in original file.\n",
    "df_ex=df_journeyLoc[df_journeyLoc.journey_start_location_name==\"Valdez Marine Terminal\"]\n",
    "df_ex1=df_journeyLoc[df_journeyLoc.journey_end_location_name==\"Valdez Marine Terminal\"]\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"We found that the overall number of journey starting from 'Valdez Marine Terminal' is {},\\n all belong to the country: \\n {}\".format(len(df_ex),df_ex[\"journey_start_location_country\"].value_counts()))\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"The same situation with the other terminals.\")\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"Therefore, the so-called duplicated terminals are not correct.\")\n",
    "print (\"A entire cleanning of the journey dataset is needed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step c): Extract all duplicate terminals from original dataset. \n",
    "Clean the data and fill all the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(df,column=\"Country\"):\n",
    "    \"\"\"\n",
    "    check if there are Null data in the given dataframe\n",
    "    df: dataframe\n",
    "    column: string, the name of checked column\n",
    "    \n",
    "    return: a dataframe with all the null data\n",
    "    \"\"\"\n",
    "    if column is None: \n",
    "        return \n",
    "    \n",
    "    df_null=df[df[column].isnull()]\n",
    "    return df_null\n",
    "\n",
    "def check_missData(df):\n",
    "    \"\"\"\n",
    "    check the missing data of dataFrame.\n",
    "    return: a dataFrame describing missing data percentage\n",
    "    sum(): count the number of missing data in each column\n",
    "    isnull(): return a dataFrame with True and False   \n",
    "    \"\"\"\n",
    "    miss_tot=df.isnull().sum().sort_values(ascending=False)\n",
    "    counts_all=df.isnull().count() # count all the elements, including the missed elements\n",
    "    miss_per=((df.isnull().sum())*100/counts_all).sort_values(ascending=False)\n",
    "    miss_all=pd.concat([miss_tot,miss_per],axis=1,keys=['TotalNum','TotalPerc(\\%)'])\n",
    "    return miss_all\n",
    "\n",
    "\n",
    "def fill_null(df,column=\"Country\",value=\"unknown\"):\n",
    "    \"\"\"\n",
    "    Fill the NaN in given column with given value\n",
    "    In case for modification, it will be updated as required.\n",
    "    \n",
    "    df: dataframe\n",
    "    column: string, the column with Null\n",
    "    value: string, the value to be filled\n",
    "    return: a dataframe with filled value\n",
    "    \"\"\"\n",
    "    df[column].fillna(value,inplace=True)\n",
    "    return df\n",
    "\n",
    "def check_dup(df,check_term=[\"Mongstad Refinery\",\"Slovag\"]):\n",
    "    \"\"\"\n",
    "    # check the original journey file if there are duplicate terminal names in different countries\n",
    "    # only suitable for dataframe with columns: journey_start_location_name,journey_end_location_name,\n",
    "    # journey_start_location_country and journey_end_location_country.\n",
    "    # checking criterion: whether or not the length of grouped dataframe with given terminals\n",
    "    # is equal to the first value of list in counted country.\n",
    "    # if so--> no duplicate terminals, otherwise, with duplicate terminals.\n",
    "    # df: dataframe\n",
    "    # check_term: checked terminals\n",
    "    # return: a list including all the duplicate terminals in given dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    if check_term is None:\n",
    "        return\n",
    "    \n",
    "    dups=[]\n",
    "    for terminal in check_term:\n",
    "        df_start_term=df[df.journey_start_location_name==terminal]\n",
    "        df_end_term=df[df.journey_end_location_name==terminal]\n",
    "        \n",
    "        if (terminal in df.journey_start_location_name.values):\n",
    "            len_start=len(df_start_term)\n",
    "            counts_start=df_start_term[\"journey_start_location_country\"].value_counts()\n",
    "            counts_start=counts_start.values\n",
    "            \n",
    "            if counts_start !=[]:\n",
    "                if (len_start!=counts_start[0]):\n",
    "                    dups.append(terminal)\n",
    "                \n",
    "        if (terminal in df.journey_end_location_name.values):\n",
    "            len_end=len(df_end_term)\n",
    "            counts_end=df_end_term[\"journey_end_location_country\"].value_counts()\n",
    "            counts_end=counts_end.values\n",
    "            \n",
    "            if counts_end !=[]:\n",
    "                if (len_end!=counts_end[0]):\n",
    "                    dups.append(terminal)\n",
    "                    \n",
    "        dups=list(set(dups))\n",
    "        \n",
    "    return dups\n",
    "\n",
    "def df_reduce(df_origin,duplicate_terms=['Cartagena', 'Vancouver']):\n",
    "    \"\"\"\n",
    "    obtain the shrinked datafrome with given terminals.\n",
    "    dataFrame format should be the same as original journey file\n",
    "    \n",
    "    df_origin: original dataframe\n",
    "    duplicate_terms: duplicate terminals, list\n",
    "    return: a dataframe with rows including only given terminals. \n",
    "    \"\"\"\n",
    "    ix=[]\n",
    "    \n",
    "    if duplicate_terms is None:\n",
    "        return\n",
    "    \n",
    "    cols=[\"journey_start_location_name\",\"journey_end_location_name\"]\n",
    "    for terminal in duplicate_terms:\n",
    "        \n",
    "        if terminal in df_origin[cols[0]].values :\n",
    "            temp=df_origin[df_origin[cols[0]]==terminal].index.tolist()\n",
    "            ix.extend(temp)\n",
    "        if terminal in df_origin[cols[1]].values:\n",
    "            temp=df_origin[df_origin[cols[1]]==terminal].index.tolist()\n",
    "            ix.extend(temp)\n",
    "            \n",
    "    ix=list(set(ix))\n",
    "    df_new=df_origin.loc[ix]\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def updateName_dup(df,duplicates=['Cartagena', 'Vancouver']):\n",
    "    \"\"\"\n",
    "    update the name for duplicates teminals\n",
    "    Note that this function will modify the data in given dataset.\n",
    "    \n",
    "    df:dataframe\n",
    "    duplicates: list, names of duplicates terminals\n",
    "    return: a dataframe with no duplicate entries anymore\n",
    "    \"\"\"\n",
    " \n",
    "    locations=[\"journey_start_location_name\",\"journey_end_location_name\"]\n",
    "    countries=[\"journey_start_location_country\",\"journey_end_location_country\"]\n",
    "    \n",
    "    if duplicates is None:\n",
    "        return\n",
    "    \n",
    "    for terminal in duplicates:\n",
    "        \n",
    "        if terminal in df[locations[0]].values:\n",
    "            ix=df[df[locations[0]]==terminal].index.tolist()\n",
    "            for i in ix:     \n",
    "                df.loc[i,locations[0]]=terminal+str(\"_\")+df.loc[i,countries[0]]\n",
    "        \n",
    "        if terminal in df[locations[1]].values:\n",
    "            ix=df[df[locations[1]]==terminal].index.tolist()\n",
    "            for i in ix:     \n",
    "                df.loc[i,locations[1]]=terminal+str(\"_\")+df.loc[i,countries[1]]   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 TotalNum  TotalPerc(\\%)\n",
      "journey_end_location_unlocode        6106       1.217958\n",
      "journey_start_location_unlocode      5093       1.015896\n",
      "journey_end_location_country         2336       0.465960\n",
      "journey_end_location_type            1754       0.349869\n",
      "journey_end_location_name            1754       0.349869\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "since there are too many Nulls, we will deal with null only after extracting data\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "This is the test case for a dataframe with one duplicated terminal: 'De Kastri' \n",
      "The duplicated terminal in the checking terminals are:  ['De Kastri']\n",
      "Validated ! \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "The first ten terminals: ['Limas Liquid Terminal', 'Setoda Harbour', 'San Juan', 'Karimun Besar', 'Koje Marine Terminal', 'Brass Terminal', 'Richards Bay Dry Bulk Terminal', 'Keelung North Container Terminal', 'Jebel Ali Container Terminal 2', 'Vado Ligure']\n",
      "The overall number of terminals from data are: 3271\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-6c7af396b795>:68: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if counts_start !=[]:\n",
      "<ipython-input-69-6c7af396b795>:77: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if counts_end !=[]:\n",
      "<ipython-input-69-6c7af396b795>:77: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if counts_end !=[]:\n",
      "<ipython-input-69-6c7af396b795>:68: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if counts_start !=[]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among all the terminals, the duplicate terminals are:\n",
      " ['Freeport', 'San Juan', 'Puerto Bolivar', 'Portland', 'Damen Ship Repair', 'Caldera', 'Tripoli', \"St John's\", 'Cartagena', 'Manzanillo', 'Louis Dreyfus Grain Terminal', 'San Lorenzo', 'San Pedro', 'Vancouver', 'Samsung', 'Matanzas', 'Georgetown']\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "The number of duplicated terminals: 17\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check Null in dataset\n",
    "df_miss=check_missData(df_journey)\n",
    "print(df_miss.head())\n",
    "print (\"-----------------------------------------------------------------------------------------------------------\")\n",
    "print (\"since there are too many Nulls, we will deal with null only after extracting data\")\n",
    "print (\"-----------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# a test case with few data is given here for a validation of function check_dup(). \n",
    "df_test=pd.read_csv(\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/journey_tests.txt\",sep=\",\")\n",
    "dups=check_dup(df_test,['De Kastri','Ulsan','caisd'])\n",
    "print (\"This is the test case for a dataframe with one duplicated terminal: 'De Kastri' \")\n",
    "print (\"The duplicated terminal in the checking terminals are: \",dups)\n",
    "print (\"Validated ! \")\n",
    "print (\"-----------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# Find all the terminals\n",
    "terminal_end=list(set(df_journey.journey_end_location_name))\n",
    "terminal_start=list(set(df_journey.journey_start_location_name))\n",
    "terminal_all=list(set(terminal_end+terminal_start))\n",
    "terminal_all= [x for x in terminal_all if x == x] # Since nan is not equal to nan (nan != nan). nan==nan--> False\n",
    "print (\"The first ten terminals:\",terminal_all[:10])\n",
    "print (\"The overall number of terminals from data are:\",len(terminal_all))\n",
    "print (\"-----------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "terminal_all_1=list(set(df_ports.Terminal))\n",
    "\n",
    "# check duplicated terminals inside jounery file using the function check_dup() !\n",
    "duplicates_terms=check_dup(df_journey,terminal_all)\n",
    "print (\"Among all the terminals, the duplicate terminals are:\\n\",duplicates_terms)\n",
    "print (\"-----------------------------------------------------------------------------------------------------------\")\n",
    "print (\"The number of duplicated terminals:\",len(duplicates_terms))\n",
    "print (\"-----------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract other corresponding data information of the duplicate terminals from the original journey file.\n",
    "Note that I manually collect the duplicate information based on found dupliate terminals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of countries the terminals belong to:\n",
      " {'Samsung': [2]}\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "The corresponding countries for each duplicate terminals:\n",
      " {'Samsung': ['South Korea', 'South Korea', 'China', 'South Korea', 'China', 'China', 'China', 'China', 'China', 'South Korea', 'China', 'South Korea', 'China', 'South Korea', 'South Korea', 'South Korea', 'South Korea', 'South Korea', 'South Korea', 'China', 'South Korea', 'South Korea', 'China', 'China', 'South Korea', 'South Korea', 'South Korea', 'South Korea', 'South Korea', 'South Korea', 'China', 'South Korea', 'South Korea', 'South Korea', 'South Korea', 'China', 'China', 'China', 'China', 'South Korea', 'China', 'South Korea', 'China']}\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "The corresponding latitude for each duplicate terminals:\n",
      " {'Samsung': [34.909909999999996, 34.91553, 29.97465, 34.90498, 29.974759999999996, 29.97472, 29.97467, 29.97474, 29.97468, 34.90723, 29.974690000000002, 34.91107, 29.97468, 34.90436, 34.90724, 34.90733, 34.9, 34.92771, 34.9097, 29.97474, 34.90302, 34.90302, 29.974659999999997, 29.97467, 34.91341, 34.90307, 34.90879, 34.91333, 34.90445, 34.903079999999996, 29.97472, 34.90313, 34.903009999999995, 34.907509999999995, 34.90887, 29.974809999999998, 29.9747, 29.974829999999997, 29.97485, 34.90752, 29.974729999999997, 34.90279, 29.974809999999998]}\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "The corresponding longitude for each duplicate terminals:\n",
      " {'Samsung': [128.59538999999998, 128.58825, 121.76817, 128.6075, 121.76825, 121.76827, 121.7682, 121.76818, 121.76822, 128.60067, 121.76818999999999, 128.58892, 121.76821000000001, 128.61047, 128.60061000000002, 128.60053, 128.61408, 128.5871, 128.58923000000001, 121.76821000000001, 128.59992, 128.59985, 121.7682, 121.7682, 128.59488000000002, 128.59993, 128.59976, 128.59482, 128.61043, 128.60003, 121.76833, 128.60027, 128.59998000000002, 128.60076, 128.59973, 121.76823, 121.76834, 121.76816000000001, 121.76822, 128.59995, 121.76835, 128.61075, 121.76823999999999]}\n"
     ]
    }
   ],
   "source": [
    "def output_dup(df,dups=['Tripoli', 'Vancouver']):\n",
    "    \"\"\"\n",
    "    extract the relevant information of duplicate terminals from original journey file based on given terminals\n",
    "    it is only suitable for dataframe with columns: journey_start_location_name, journey_start_location_country,\n",
    "    journey_start_latitude and journey_start_longitude.\n",
    "    use the starting points to trace other relevant information. \n",
    "    \n",
    "    df: dataFrame\n",
    "    dups: duplicate terminals\n",
    "    return: dictionaries including the number of cuntries of each terminal, countries, latitudes, and longitudes.\n",
    "    \"\"\"\n",
    "    countries={}\n",
    "    lats={}\n",
    "    lons={}\n",
    "    country_num={}\n",
    "    for terminal in dups:\n",
    "        ix=df[df[\"journey_start_location_name\"]==terminal].index.values\n",
    "        for i in ix:\n",
    "            countries.setdefault(terminal,[]).append(df.loc[i,\"journey_start_location_country\"])\n",
    "            lats.setdefault(terminal,[]).append(df.loc[i,\"journey_start_latitude\"])\n",
    "            lons.setdefault(terminal,[]).append(df.loc[i,\"journey_start_longitude\"])\n",
    "        country_num.setdefault(terminal,[]).append(len(set(countries[terminal])))\n",
    "    return country_num,countries,lats,lons\n",
    "\n",
    "country_num,countries,lats,lons=output_dup(df_journey,['Samsung'])\n",
    "print (\"The number of countries the terminals belong to:\\n\",country_num)\n",
    "print (\"----------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"The corresponding countries for each duplicate terminals:\\n\",countries)\n",
    "print (\"----------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"The corresponding latitude for each duplicate terminals:\\n\",lats)\n",
    "print (\"----------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"The corresponding longitude for each duplicate terminals:\\n\",lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journey_start_location_type</th>\n",
       "      <th>journey_start_location_country</th>\n",
       "      <th>journey_start_location_name</th>\n",
       "      <th>journey_start_latitude</th>\n",
       "      <th>journey_start_longitude</th>\n",
       "      <th>journey_end_location_type</th>\n",
       "      <th>journey_end_location_country</th>\n",
       "      <th>journey_end_location_name</th>\n",
       "      <th>journey_end_latitude</th>\n",
       "      <th>journey_end_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>Port</td>\n",
       "      <td>Caribbean Netherlands</td>\n",
       "      <td>St Eustatius</td>\n",
       "      <td>17.50264</td>\n",
       "      <td>-63.00621</td>\n",
       "      <td>Port</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>18.43056</td>\n",
       "      <td>-66.11004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>Port</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>Klaipeda Nafta Oil Terminal</td>\n",
       "      <td>55.72612</td>\n",
       "      <td>21.09402</td>\n",
       "      <td>Port</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>18.43065</td>\n",
       "      <td>-66.10993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     journey_start_location_type journey_start_location_country  \\\n",
       "5989                        Port          Caribbean Netherlands   \n",
       "6652                        Port                      Lithuania   \n",
       "\n",
       "      journey_start_location_name  journey_start_latitude  \\\n",
       "5989                 St Eustatius                17.50264   \n",
       "6652  Klaipeda Nafta Oil Terminal                55.72612   \n",
       "\n",
       "      journey_start_longitude journey_end_location_type  \\\n",
       "5989                -63.00621                      Port   \n",
       "6652                 21.09402                      Port   \n",
       "\n",
       "     journey_end_location_country journey_end_location_name  \\\n",
       "5989                  Puerto Rico                  San Juan   \n",
       "6652                  Puerto Rico                  San Juan   \n",
       "\n",
       "      journey_end_latitude  journey_end_longitude  \n",
       "5989              18.43056              -66.11004  \n",
       "6652              18.43065              -66.10993  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find information for some exception duplicate terminals.\n",
    "# The terminal Bermuda is hidding among a bunch of Bahamas. \n",
    "# Check the Bermuda port \n",
    "terminal_bermuda=df_journeyLoc[(df_journeyLoc.journey_end_location_country==\"Bermuda\") & (df_journeyLoc.journey_end_location_name==\"Freeport\")]\n",
    "#print (terminal_bermuda.head())\n",
    "\n",
    "# The terminal St John's is hidding among a bunch of Antigua & Barbuda. \n",
    "# Check the St John's port in Canada\n",
    "terminal_st=df_journeyLoc[(df_journeyLoc.journey_end_location_country==\"Canada\") & (df_journeyLoc.journey_end_location_name==\"St John's\")]\n",
    "#print (terminal_st.head())\n",
    "\n",
    "# The terminal San Juan is hidding among a bunch of Puerto Rico. \n",
    "# Check the San Juan port in Panama\n",
    "terminal_sj=df_journeyLoc[(df_journeyLoc.journey_end_location_country==\"Puerto Rico\") & (df_journeyLoc.journey_end_location_name==\"San Juan\")]\n",
    "terminal_sj.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Load the found duplicate terminals informaiton, and update the duplicate terminals in original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among all the terminals, the duplicate terminals are:\n",
      " ['Freeport', 'San Juan', 'Puerto Bolivar', 'Portland', 'Damen Ship Repair', 'Caldera', 'Tripoli', \"St John's\", 'Cartagena', 'Manzanillo', 'Louis Dreyfus Grain Terminal', 'San Lorenzo', 'San Pedro', 'Vancouver', 'Samsung', 'Matanzas', 'Georgetown']\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-6c7af396b795>:68: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if counts_start !=[]:\n",
      "<ipython-input-69-6c7af396b795>:77: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if counts_end !=[]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in the dataset with updated names []\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "The new overall number of terminals are: 3288\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "The first ten terminals:\n",
      " ['Limas Liquid Terminal', 'Setoda Harbour', 'Karimun Besar', 'Koje Marine Terminal', 'Brass Terminal', 'Richards Bay Dry Bulk Terminal', 'Keelung North Container Terminal', 'Jebel Ali Container Terminal 2', 'Vado Ligure', 'Fort de France']\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "As we noticed, the added terminal name is 17 due to duplicates. Thus, the overall terminals should be 3288 in total \n",
      ", matching with the number we account.\n",
      "New dataset is clean with no Duplicats !!!!!\n",
      "Great ! No duplicates !!!\n",
      "---------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# read the extracted duplicate data, which are based on the cleaning above. \n",
    "df_dupTerm=pd.ExcelFile(\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/portList_duplicate.xlsx\")\n",
    "df_dupTerm=df_dupTerm.parse(header=0,index_col=0)\n",
    "\n",
    "# the duplicated terminals computed above are presented here as well\n",
    "print (\"Among all the terminals, the duplicate terminals are:\\n\",duplicates_terms)\n",
    "print (\"-------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# update the name of duplicated terminals in original journey file.\n",
    "df_journey_copy=df_journey.copy()\n",
    "df_journey_new=updateName_dup(df_journey_copy,duplicates_terms)\n",
    "\n",
    "# re-check the new dataframe if there are duplicates\n",
    "duplicates_terms1=check_dup(df_journey_new,terminal_all)\n",
    "print (\"Duplicates in the dataset with updated names\",duplicates_terms1)\n",
    "\n",
    "# re-check the number of duplicates, and to validate the new dataset\n",
    "terminals_1=list(set(df_journey_new.journey_start_location_name))\n",
    "terminals_2=list(set(df_journey_new.journey_end_location_name))\n",
    "terminals_new_all=list(set(terminals_1+terminals_2))\n",
    "terminals_new_all=[x for x in terminals_new_all if x==x]\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"The new overall number of terminals are:\",len(terminals_new_all))\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"The first ten terminals:\\n\",terminals_new_all[:10])\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"As we noticed, the added terminal name is 17 due to duplicates. Thus, the overall terminals should be 3288 in total \\n, matching with the number we account.\")\n",
    "print (\"New dataset is clean with no Duplicats !!!!!\")\n",
    "print (\"Great ! No duplicates !!!\")\n",
    "print (\"---------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step d): Find the number of calls for new cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_valsCount(df):\n",
    "    \"\"\"\n",
    "    check the number of counts of each value in dataframe\n",
    "    df: a dataframe\n",
    "    return: a list including all the counts of each column\n",
    "    \"\"\"\n",
    "    cols=df.columns\n",
    "    counts_all=[]\n",
    "    for col in cols:\n",
    "        counts=df.loc[:,col].value_counts()\n",
    "        counts_all.append(counts)\n",
    "        print (counts)\n",
    "        print ('\\n')\n",
    "    return counts_all\n",
    "\n",
    "def drop_dups(df,dups=['Cartagena', 'Freeport']):\n",
    "    \"\"\"\n",
    "    Given a list of terminals, obtaining a new dataframe by removing these terminals.\n",
    "    df:dataframe\n",
    "    dups: list including removed terminals\n",
    "    Note that the original dataframe is modified here. \n",
    "    lease make a copy of the orignal dataframe.\n",
    "    \n",
    "    return: a new dataframe\n",
    "    \"\"\"\n",
    "    cols=[\"journey_start_location_name\",\"journey_end_location_name\"]\n",
    "    for terminal in dups:\n",
    "        # get the index of duplicated terminal\n",
    "        ix_1=df[df[\"journey_start_location_name\"]==terminal].index.tolist()\n",
    "        ix_2=df[df[\"journey_end_location_name\"]==terminal].index.tolist()\n",
    "        ix=ix_1+ix_2\n",
    "        \n",
    "        df.drop(ix,axis=0,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def findCalls(df):\n",
    "    \"\"\"\n",
    "    to compute the number of calls for each terminal based on the number of occurrence in both start port or end port. \n",
    "    save results into a dict, with each terminal as the key.\n",
    "    \n",
    "    df: dataframe\n",
    "    return: a new dataframe with columns:\"Terminal\",\"number of call start\",\"number of call end\",\"number of call all\".    \n",
    "    \"\"\"\n",
    "    cols=[\"journey_start_location_name\",\"journey_end_location_name\"]\n",
    "    counts_all=[]\n",
    "    for col in cols:\n",
    "        counts=df.loc[:,col].value_counts()\n",
    "        counts_all.append(counts)\n",
    "    df_counts=pd.concat(counts_all,axis=1)\n",
    "    df_counts[\"number of call all\"]=df_counts.sum(axis=1)\n",
    "    df_counts=df_counts.reset_index()\n",
    "    df_counts.columns=[\"Terminal\",\"number of call start\",\"number of call end\",\"number of call all\"]\n",
    "    df_counts.fillna(0,inplace=True)\n",
    "    \n",
    "    return df_counts\n",
    "\n",
    "def find_Country_Loction(df,terminals=[]):\n",
    "    \"\"\"\n",
    "    find other information for a given list of terminals, including countries, and location info, etc.\n",
    "    \n",
    "    df:dataframe\n",
    "    return: a dataframe including terminals and other information.   \n",
    "    \"\"\"\n",
    "    countries={}\n",
    "    lats={}\n",
    "    lons={}\n",
    "    \n",
    "    if terminals is None:\n",
    "        return \n",
    "    \n",
    "    for terminal in terminals:\n",
    "        if terminal in df.journey_start_location_name.values:\n",
    "            ix=df[df[\"journey_start_location_name\"]==terminal].index[0]\n",
    "            countries.setdefault(terminal,[]).append(df.loc[ix,\"journey_start_location_country\"])\n",
    "            lats.setdefault(terminal,[]).append(df.loc[ix,\"journey_start_latitude\"])\n",
    "            lons.setdefault(terminal,[]).append(df.loc[ix,\"journey_start_longitude\"])\n",
    "        elif terminal in df.journey_end_location_name.values:\n",
    "            ix=df[df[\"journey_end_location_name\"]==terminal].index[0]\n",
    "            countries.setdefault(terminal,[]).append(df.loc[ix,\"journey_end_location_country\"])\n",
    "            lats.setdefault(terminal,[]).append(df.loc[ix,\"journey_end_latitude\"])\n",
    "            lons.setdefault(terminal,[]).append(df.loc[ix,\"journey_end_longitude\"])\n",
    "    countries=pd.DataFrame(countries).T\n",
    "    lat=pd.DataFrame(lats).T\n",
    "    lon=pd.DataFrame(lons).T\n",
    "    conLoc=pd.concat([countries,lat,lon],axis=1)\n",
    "    conLoc=conLoc.reset_index()\n",
    "    conLoc.columns=[\"Terminal\",\"Country\",\"Lat\",\"Lon\"]\n",
    "    return conLoc   \n",
    "    \n",
    "def merge_df(df1,df2,byCol=\"Terminal\",how=\"outer\"):\n",
    "    \"\"\"\n",
    "    merge given dataframes\n",
    "    df1:dataframe1\n",
    "    df2:dataframe2\n",
    "    byCol: the index colomn for merge\n",
    "    how: the way to merge\n",
    "    \n",
    "    return: a new merged dataframe\n",
    "    \"\"\"\n",
    "    df_all=pd.merge(df1,df2,how=how,on=byCol)\n",
    "    return df_all\n",
    "\n",
    "def saveDf(df,dirs=\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/savedFile/\",fileName=\"portsInfo.csv\"):\n",
    "    \"\"\"\n",
    "    save dataframe into csv file\n",
    "    df: dataframe needed to be save\n",
    "    \n",
    "    dirs: directory to be saved, string\n",
    "    fileName: string\n",
    "    return: None\n",
    "    \"\"\"\n",
    "    df.to_csv(dirs+fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journey_id</th>\n",
       "      <th>ship_id</th>\n",
       "      <th>ais_ship_id</th>\n",
       "      <th>journey_laden</th>\n",
       "      <th>journey_start_stoppage_id</th>\n",
       "      <th>journey_start_timestamp</th>\n",
       "      <th>journey_start_draft</th>\n",
       "      <th>journey_start_latitude</th>\n",
       "      <th>journey_start_longitude</th>\n",
       "      <th>journey_start_location_type</th>\n",
       "      <th>...</th>\n",
       "      <th>journey_end_location_name</th>\n",
       "      <th>journey_end_location_country</th>\n",
       "      <th>journey_end_location_unlocode</th>\n",
       "      <th>journey_distance_nm</th>\n",
       "      <th>journey_underway_calc_avg_speed</th>\n",
       "      <th>journey_processed</th>\n",
       "      <th>journey_current</th>\n",
       "      <th>journey_estimated_cargo_tons</th>\n",
       "      <th>journey_underway_distance</th>\n",
       "      <th>journey_underway_time_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286559091</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>886369008</td>\n",
       "      <td>2013-12-30 05:34:03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.45277</td>\n",
       "      <td>140.92767</td>\n",
       "      <td>Port</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeosu</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>KRYOS</td>\n",
       "      <td>1247.352457</td>\n",
       "      <td>13.959216</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>98235</td>\n",
       "      <td>1195.141506</td>\n",
       "      <td>85.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286559092</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>886369009</td>\n",
       "      <td>2014-01-07 13:30:04</td>\n",
       "      <td>14.2</td>\n",
       "      <td>34.71473</td>\n",
       "      <td>127.81125</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>...</td>\n",
       "      <td>De Kastri</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUDKA</td>\n",
       "      <td>1251.511628</td>\n",
       "      <td>13.074002</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1233.310535</td>\n",
       "      <td>94.333056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>286559093</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>886369012</td>\n",
       "      <td>2014-01-19 01:02:19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.48012</td>\n",
       "      <td>140.92478</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>...</td>\n",
       "      <td>Ulsan</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>KRUSN</td>\n",
       "      <td>1166.283499</td>\n",
       "      <td>14.453006</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>98235</td>\n",
       "      <td>1132.023627</td>\n",
       "      <td>78.324444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286559094</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>886369014</td>\n",
       "      <td>2014-01-25 05:06:44</td>\n",
       "      <td>14.2</td>\n",
       "      <td>35.44117</td>\n",
       "      <td>129.39453</td>\n",
       "      <td>Port</td>\n",
       "      <td>...</td>\n",
       "      <td>De Kastri</td>\n",
       "      <td>Russia</td>\n",
       "      <td>RUDKA</td>\n",
       "      <td>1339.352542</td>\n",
       "      <td>13.024184</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1197.562825</td>\n",
       "      <td>91.949167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286559095</td>\n",
       "      <td>9301421</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>886369018</td>\n",
       "      <td>2014-02-05 12:23:14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.48157</td>\n",
       "      <td>140.92332</td>\n",
       "      <td>Port</td>\n",
       "      <td>...</td>\n",
       "      <td>Gwangyang</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>KRKAN</td>\n",
       "      <td>1299.165114</td>\n",
       "      <td>13.671880</td>\n",
       "      <td>2019-03-28 06:53:38</td>\n",
       "      <td>0</td>\n",
       "      <td>98235</td>\n",
       "      <td>1288.684831</td>\n",
       "      <td>94.258056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   journey_id  ship_id  ais_ship_id  journey_laden  journey_start_stoppage_id  \\\n",
       "0   286559091  9301421           97              1                  886369008   \n",
       "1   286559092  9301421           97              0                  886369009   \n",
       "2   286559093  9301421           97              1                  886369012   \n",
       "3   286559094  9301421           97              0                  886369014   \n",
       "4   286559095  9301421           97              1                  886369018   \n",
       "\n",
       "  journey_start_timestamp  journey_start_draft  journey_start_latitude  \\\n",
       "0     2013-12-30 05:34:03                  9.0                51.45277   \n",
       "1     2014-01-07 13:30:04                 14.2                34.71473   \n",
       "2     2014-01-19 01:02:19                  9.0                51.48012   \n",
       "3     2014-01-25 05:06:44                 14.2                35.44117   \n",
       "4     2014-02-05 12:23:14                  9.0                51.48157   \n",
       "\n",
       "   journey_start_longitude journey_start_location_type  ...  \\\n",
       "0                140.92767                        Port  ...   \n",
       "1                127.81125                   Anchorage  ...   \n",
       "2                140.92478                   Anchorage  ...   \n",
       "3                129.39453                        Port  ...   \n",
       "4                140.92332                        Port  ...   \n",
       "\n",
       "  journey_end_location_name journey_end_location_country  \\\n",
       "0                     Yeosu                  South Korea   \n",
       "1                 De Kastri                       Russia   \n",
       "2                     Ulsan                  South Korea   \n",
       "3                 De Kastri                       Russia   \n",
       "4                 Gwangyang                  South Korea   \n",
       "\n",
       "  journey_end_location_unlocode  journey_distance_nm  \\\n",
       "0                         KRYOS          1247.352457   \n",
       "1                         RUDKA          1251.511628   \n",
       "2                         KRUSN          1166.283499   \n",
       "3                         RUDKA          1339.352542   \n",
       "4                         KRKAN          1299.165114   \n",
       "\n",
       "  journey_underway_calc_avg_speed    journey_processed  journey_current  \\\n",
       "0                       13.959216  2019-03-28 06:53:38                0   \n",
       "1                       13.074002  2019-03-28 06:53:38                0   \n",
       "2                       14.453006  2019-03-28 06:53:38                0   \n",
       "3                       13.024184  2019-03-28 06:53:38                0   \n",
       "4                       13.671880  2019-03-28 06:53:38                0   \n",
       "\n",
       "   journey_estimated_cargo_tons journey_underway_distance  \\\n",
       "0                         98235               1195.141506   \n",
       "1                             0               1233.310535   \n",
       "2                         98235               1132.023627   \n",
       "3                             0               1197.562825   \n",
       "4                         98235               1288.684831   \n",
       "\n",
       "  journey_underway_time_hours  \n",
       "0                   85.616667  \n",
       "1                   94.333056  \n",
       "2                   78.324444  \n",
       "3                   91.949167  \n",
       "4                   94.258056  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_journey_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the number of calls for each terminal\n",
    "df_counts_new=findCalls(df_journey_new)\n",
    "\n",
    "# find other information related to terminals\n",
    "terminals_new=df_counts_new.Terminal.values\n",
    "df_countries_new=find_Country_Loction(df_journey_new,terminals_new)\n",
    "\n",
    "# merge the two datafarmes\n",
    "df_all=merge_df(df_countries_new,df_counts_new,byCol=\"Terminal\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terminal</th>\n",
       "      <th>number of call start</th>\n",
       "      <th>number of call end</th>\n",
       "      <th>number of call all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>7403.0</td>\n",
       "      <td>7365.0</td>\n",
       "      <td>14768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PTP Terminal</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>7566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novorossiysk</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>7524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeosu</td>\n",
       "      <td>3531.0</td>\n",
       "      <td>3547.0</td>\n",
       "      <td>7078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>3375.0</td>\n",
       "      <td>6746.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Terminal  number of call start  number of call end  number of call all\n",
       "0     Singapore                7403.0              7365.0             14768.0\n",
       "1  PTP Terminal                3785.0              3781.0              7566.0\n",
       "2  Novorossiysk                3762.0              3762.0              7524.0\n",
       "3         Yeosu                3531.0              3547.0              7078.0\n",
       "4       Houston                3371.0              3375.0              6746.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new data\n",
    "df_counts_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terminal</th>\n",
       "      <th>Country</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.20470</td>\n",
       "      <td>103.67232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PTP Terminal</td>\n",
       "      <td>Russia</td>\n",
       "      <td>60.32058</td>\n",
       "      <td>28.72898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novorossiysk</td>\n",
       "      <td>Russia</td>\n",
       "      <td>44.72680</td>\n",
       "      <td>37.78154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeosu</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>34.71473</td>\n",
       "      <td>127.81125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>29.23550</td>\n",
       "      <td>-94.62350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Terminal                   Country       Lat        Lon\n",
       "0     Singapore                 Singapore   1.20470  103.67232\n",
       "1  PTP Terminal                    Russia  60.32058   28.72898\n",
       "2  Novorossiysk                    Russia  44.72680   37.78154\n",
       "3         Yeosu               South Korea  34.71473  127.81125\n",
       "4       Houston  United States of America  29.23550  -94.62350"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terminal</th>\n",
       "      <th>Country</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>number of call start</th>\n",
       "      <th>number of call end</th>\n",
       "      <th>number of call all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.20470</td>\n",
       "      <td>103.67232</td>\n",
       "      <td>7403.0</td>\n",
       "      <td>7365.0</td>\n",
       "      <td>14768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PTP Terminal</td>\n",
       "      <td>Russia</td>\n",
       "      <td>60.32058</td>\n",
       "      <td>28.72898</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>7566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novorossiysk</td>\n",
       "      <td>Russia</td>\n",
       "      <td>44.72680</td>\n",
       "      <td>37.78154</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>7524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeosu</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>34.71473</td>\n",
       "      <td>127.81125</td>\n",
       "      <td>3531.0</td>\n",
       "      <td>3547.0</td>\n",
       "      <td>7078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>29.23550</td>\n",
       "      <td>-94.62350</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>3375.0</td>\n",
       "      <td>6746.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Terminal                   Country       Lat        Lon  \\\n",
       "0     Singapore                 Singapore   1.20470  103.67232   \n",
       "1  PTP Terminal                    Russia  60.32058   28.72898   \n",
       "2  Novorossiysk                    Russia  44.72680   37.78154   \n",
       "3         Yeosu               South Korea  34.71473  127.81125   \n",
       "4       Houston  United States of America  29.23550  -94.62350   \n",
       "\n",
       "   number of call start  number of call end  number of call all  \n",
       "0                7403.0              7365.0             14768.0  \n",
       "1                3785.0              3781.0              7566.0  \n",
       "2                3762.0              3762.0              7524.0  \n",
       "3                3531.0              3547.0              7078.0  \n",
       "4                3371.0              3375.0              6746.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final round of checking, and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Terminal              0 non-null      object \n",
      " 1   Country               0 non-null      object \n",
      " 2   Lat                   0 non-null      float64\n",
      " 3   Lon                   0 non-null      float64\n",
      " 4   number of call start  0 non-null      float64\n",
      " 5   number of call end    0 non-null      float64\n",
      " 6   number of call all    0 non-null      float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 0.0+ bytes\n",
      "None\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Final round of checking for the cleaned dataset df_all\n",
    "check_missData(df_all)\n",
    "\n",
    "# Fill the Country in NaN with \"unknown\"\n",
    "df_all=fill_null(df_all,column=\"Country\",value=\"unknown\")\n",
    "\n",
    "# to check if any ohter Null values\n",
    "df_null=check_null(df_all,column=\"Country\")\n",
    "print (\"---------------------------------------------------------------------------------------------------------------\")\n",
    "print (df_null.info())\n",
    "print (\"---------------------------------------------------------------------------------------------------------------\")\n",
    "print (\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaned portInfor.csv has been sucessfully saved to the file 'C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/savedFile'\n"
     ]
    }
   ],
   "source": [
    "saveDf(df_all,dirs=\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/savedFile/\",fileName=\"portsInfo.csv\")\n",
    "print (\"The cleaned portInfor.csv has been sucessfully saved to the file 'C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/savedFile'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.excel import ExcelWriter\n",
    "import pandas\n",
    "\n",
    "# save data from csv to excel format\n",
    "csv_files = ['portsInfo_1.csv']\n",
    "with ExcelWriter(\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/\"+'portsInfo.xlsx') as ew:\n",
    "    for csv_file in csv_files:\n",
    "        pandas.read_csv(\"C:/posDoc-SDU-Denmark/SDU_research/shippingLabwp1/\"+csv_file).to_excel(ew, sheet_name=csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
